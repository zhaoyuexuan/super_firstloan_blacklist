{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84305985-cce2-49fc-a197-e1aac78ef742",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import time\n",
    "\n",
    "from data_io.oss.obs_client import ObsLib\n",
    "from data_io.mongo.mongo_client import MongoPoolDao\n",
    "from data_io.mysql.mysql_client import MysqlPoolDao\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from tqdm.contrib.concurrent import thread_map \n",
    "\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "from prefect import task, Flow, Parameter\n",
    "from prefect.executors import LocalDaskExecutor\n",
    "from prefect.schedules import IntervalSchedule\n",
    "from datetime import timedelta, datetime\n",
    "import pendulum\n",
    "\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b7dc15a-115a-4049-b682-77c04ce97228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A separator used to break the code into two parts to aid memorability.\n",
    "SEPARATOR_ = '+'\n",
    "\n",
    "# The number of characters to place before the separator.\n",
    "SEPARATOR_POSITION_ = 8\n",
    "\n",
    "# The character used to pad codes.\n",
    "PADDING_CHARACTER_ = '0'\n",
    "\n",
    "# The character set used to encode the values.\n",
    "CODE_ALPHABET_ = '23456789CFGHJMPQRVWX'\n",
    "\n",
    "# The base to use to convert numbers to/from.\n",
    "ENCODING_BASE_ = len(CODE_ALPHABET_)\n",
    "\n",
    "# The maximum value for latitude in degrees.\n",
    "LATITUDE_MAX_ = 90\n",
    "\n",
    "# The maximum value for longitude in degrees.\n",
    "LONGITUDE_MAX_ = 180\n",
    "\n",
    "# The max number of digits to process in a plus code.\n",
    "MAX_DIGIT_COUNT_ = 15\n",
    "\n",
    "# Maximum code length using lat/lng pair encoding. The area of such a\n",
    "# code is approximately 13x13 meters (at the equator), and should be suitable\n",
    "# for identifying buildings. This excludes prefix and separator characters.\n",
    "PAIR_CODE_LENGTH_ = 10\n",
    "\n",
    "# First place value of the pairs (if the last pair value is 1).\n",
    "PAIR_FIRST_PLACE_VALUE_ = ENCODING_BASE_**(PAIR_CODE_LENGTH_ / 2 - 1)\n",
    "\n",
    "# Inverse of the precision of the pair section of the code.\n",
    "PAIR_PRECISION_ = ENCODING_BASE_**3\n",
    "\n",
    "# The resolution values in degrees for each position in the lat/lng pair\n",
    "# encoding. These give the place value of each position, and therefore the\n",
    "# dimensions of the resulting area.\n",
    "PAIR_RESOLUTIONS_ = [20.0, 1.0, .05, .0025, .000125]\n",
    "\n",
    "# Number of digits in the grid precision part of the code.\n",
    "GRID_CODE_LENGTH_ = MAX_DIGIT_COUNT_ - PAIR_CODE_LENGTH_\n",
    "\n",
    "# Number of columns in the grid refinement method.\n",
    "GRID_COLUMNS_ = 4\n",
    "\n",
    "# Number of rows in the grid refinement method.\n",
    "GRID_ROWS_ = 5\n",
    "\n",
    "# First place value of the latitude grid (if the last place is 1).\n",
    "GRID_LAT_FIRST_PLACE_VALUE_ = GRID_ROWS_**(GRID_CODE_LENGTH_ - 1)\n",
    "\n",
    "# First place value of the longitude grid (if the last place is 1).\n",
    "GRID_LNG_FIRST_PLACE_VALUE_ = GRID_COLUMNS_**(GRID_CODE_LENGTH_ - 1)\n",
    "\n",
    "# Multiply latitude by this much to make it a multiple of the finest\n",
    "# precision.\n",
    "FINAL_LAT_PRECISION_ = PAIR_PRECISION_ * GRID_ROWS_**(MAX_DIGIT_COUNT_ -\n",
    "                                                      PAIR_CODE_LENGTH_)\n",
    "\n",
    "# Multiply longitude by this much to make it a multiple of the finest\n",
    "# precision.\n",
    "FINAL_LNG_PRECISION_ = PAIR_PRECISION_ * GRID_COLUMNS_**(MAX_DIGIT_COUNT_ -\n",
    "                                                         PAIR_CODE_LENGTH_)\n",
    "\n",
    "# Minimum length of a code that can be shortened.\n",
    "MIN_TRIMMABLE_CODE_LEN_ = 6\n",
    "\n",
    "GRID_SIZE_DEGREES_ = 0.000125\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60557ba4-94ba-4936-ad3f-542c474c7d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewLocationCode:\n",
    "    \n",
    "    @classmethod\n",
    "    def encode(cls, latitude, longitude, codeLength=PAIR_CODE_LENGTH_):\n",
    "        if codeLength < 2 or (codeLength < PAIR_CODE_LENGTH_ and\n",
    "                              codeLength % 2 == 1):\n",
    "            raise ValueError('Invalid Open Location Code length - ' +\n",
    "                             str(codeLength))\n",
    "        codeLength = min(codeLength, MAX_DIGIT_COUNT_)\n",
    "        # Ensure that latitude and longitude are valid.\n",
    "        latitude = cls.clipLatitude(latitude)\n",
    "        longitude = cls.normalizeLongitude(longitude)\n",
    "        # Latitude 90 needs to be adjusted to be just less, so the returned code\n",
    "        # can also be decoded.\n",
    "        if latitude == 90:\n",
    "            latitude = latitude - cls.computeLatitudePrecision(codeLength)\n",
    "        code = ''\n",
    "\n",
    "        # Compute the code.\n",
    "        # This approach converts each value to an integer after multiplying it by\n",
    "        # the final precision. This allows us to use only integer operations, so\n",
    "        # avoiding any accumulation of floating point representation errors.\n",
    "\n",
    "        # Multiply values by their precision and convert to positive.\n",
    "        # Force to integers so the division operations will have integer results.\n",
    "        # Note: Python requires rounding before truncating to ensure precision!\n",
    "        latVal = int(round((latitude + LATITUDE_MAX_) * FINAL_LAT_PRECISION_, 6))\n",
    "        lngVal = int(round((longitude + LONGITUDE_MAX_) * FINAL_LNG_PRECISION_, 6))\n",
    "\n",
    "        # Compute the grid part of the code if necessary.\n",
    "        if codeLength > PAIR_CODE_LENGTH_:\n",
    "            for i in range(0, MAX_DIGIT_COUNT_ - PAIR_CODE_LENGTH_):\n",
    "                latDigit = latVal % GRID_ROWS_\n",
    "                lngDigit = lngVal % GRID_COLUMNS_\n",
    "                ndx = latDigit * GRID_COLUMNS_ + lngDigit\n",
    "                code = CODE_ALPHABET_[ndx] + code\n",
    "                latVal //= GRID_ROWS_\n",
    "                lngVal //= GRID_COLUMNS_\n",
    "        else:\n",
    "            latVal //= pow(GRID_ROWS_, GRID_CODE_LENGTH_)\n",
    "            lngVal //= pow(GRID_COLUMNS_, GRID_CODE_LENGTH_)\n",
    "        # Compute the pair section of the code.\n",
    "        for i in range(0, PAIR_CODE_LENGTH_ // 2):\n",
    "            code = CODE_ALPHABET_[lngVal % ENCODING_BASE_] + code\n",
    "            code = CODE_ALPHABET_[latVal % ENCODING_BASE_] + code\n",
    "            latVal //= ENCODING_BASE_\n",
    "            lngVal //= ENCODING_BASE_\n",
    "\n",
    "        # Add the separator character.\n",
    "        code = code[:SEPARATOR_POSITION_] + SEPARATOR_ + code[SEPARATOR_POSITION_:]\n",
    "\n",
    "        # If we don't need to pad the code, return the requested section.\n",
    "        if codeLength >= SEPARATOR_POSITION_:\n",
    "            return code[0:codeLength + 1]\n",
    "\n",
    "        # Pad and return the code.\n",
    "        return code[0:codeLength] + SEPARATOR_\n",
    "    \n",
    "    @classmethod\n",
    "    def clipLatitude(cls, latitude):\n",
    "        return min(90, max(-90, latitude))\n",
    "    \n",
    "    @classmethod\n",
    "    def computeLatitudePrecision(cls, codeLength):\n",
    "        if codeLength <= 10:\n",
    "            return pow(20, math.floor((codeLength / -2) + 2))\n",
    "        return pow(20, -3) / pow(GRID_ROWS_, codeLength - 10)\n",
    "    \n",
    "    @classmethod\n",
    "    def normalizeLongitude(cls, longitude):\n",
    "        while longitude < -180:\n",
    "            longitude = longitude + 360\n",
    "        while longitude >= 180:\n",
    "            longitude = longitude - 360\n",
    "        return longitude\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5de7bae-6b2c-4db9-a167-b0367406ee51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlusCodeBlackList:\n",
    "    \n",
    "    # 首贷放款订单（全量）\n",
    "    @classmethod\n",
    "    def total_orders_first(cls):\n",
    "        db_super = MysqlPoolDao(202102)\n",
    "        total_orders=db_super.get_many('''\n",
    "        select\n",
    "            repay_plan.order_id,\n",
    "            check_status,\n",
    "            FROM_UNIXTIME(repay_plan.repay_date/1000, \"%Y-%m-%d\") repay_date,\n",
    "            is_reloan,\n",
    "            repay_plan.overdue_days\n",
    "        from orders inner join repay_plan on orders.id=repay_plan.order_id\n",
    "        where check_status in (8,9) and is_reloan=0\n",
    "        '''\n",
    "        )\n",
    "        return total_orders\n",
    "    \n",
    "    # 首贷到期订单（14天增量）\n",
    "    @classmethod\n",
    "    def increase_orders_first(cls):\n",
    "        db_super = MysqlPoolDao(202102)\n",
    "        \n",
    "        current_date = pd.Timestamp.now().strftime('%Y-%m-%d')\n",
    "        current_date = int(time.mktime(time.strptime(current_date, '%Y-%m-%d')))\n",
    "        \n",
    "        increase_orders = db_super.get_many('''\n",
    "        select\n",
    "            repay_plan.order_id,\n",
    "            check_status,\n",
    "            FROM_UNIXTIME(repay_plan.repay_date/1000, \"%Y-%m-%d\") repay_date,\n",
    "            is_reloan,\n",
    "            repay_plan.overdue_days\n",
    "        from orders inner join repay_plan on orders.id=repay_plan.order_id\n",
    "        where check_status in (8,9) and is_reloan=0 and repay_plan.repay_date/1000 <= '{current_date}' and repay_plan.repay_date/1000 > UNIX_TIMESTAMP((now()-INTERVAL 14 DAY))\n",
    "        '''.format(current_date = current_date)\n",
    "        )\n",
    "        return increase_orders\n",
    "    \n",
    "    \n",
    "    #GPS\n",
    "    @classmethod\n",
    "    def get_plus_code(cls, bx):\n",
    "        mongo_client = MongoPoolDao().get_mongo_client()\n",
    "        origin_dao = mongo_client['mexico']['origin_data']\n",
    "        i = bx['order_id']\n",
    "        bean = origin_dao.find_one({'order_id':i},{'file_key':1})\n",
    "        if not bean: \n",
    "            bx['plus_code'] = None\n",
    "            return \n",
    "        file_key = bean['file_key']\n",
    "        d = ObsLib.obs_get(file_key)['user_auth']['base']\n",
    "        if d['lon'] and d['lat']:\n",
    "            plus_code = NewLocationCode.encode(float(d['lat']), float(d['lon']))\n",
    "            bx['plus_code'] = plus_code\n",
    "            bx['lat'] =  d['lat']\n",
    "            bx['lon'] = d['lon']\n",
    "        else:\n",
    "            bx['plus_code'] = None\n",
    "    \n",
    "    @classmethod\n",
    "    def get_original_blacklist(cls, orders_first, plus_codes):\n",
    "        plus_code_apply_dic = defaultdict(int)\n",
    "        plus_code_overdue_dic = defaultdict(int)\n",
    "        \n",
    "        # 截取pluscode前六位\n",
    "        for i in tqdm(orders_first):\n",
    "            plus_code = i['plus_code']\n",
    "            if plus_code and plus_code[:6]+'+' in plus_codes:\n",
    "                plus_code_apply_dic[plus_code[:6]+'+']+=1\n",
    "                if i['overdue_days']>3:\n",
    "                    plus_code_overdue_dic[plus_code[:6]+'+']+=1\n",
    "\n",
    "        beans_code = []\n",
    "        for i in plus_codes:\n",
    "            beans_code.append({\n",
    "                'code_id':i,\n",
    "                'apply_cnt':plus_code_apply_dic[i],\n",
    "                'overdue_cnt':plus_code_overdue_dic[i]\n",
    "            })\n",
    "        df_code = pd.DataFrame(beans_code)\n",
    "        df_code = df_code[df_code.code_id != '8PFRWC+']\n",
    "        df_code['rate'] = df_code['overdue_cnt']/df_code['apply_cnt']\n",
    "#         df_code[(df_code['apply_cnt']>10) & (df_code['rate']>.5)].to_csv(\"pluscode_blacklist.csv\", index=False)\n",
    "        return df_code\n",
    "    \n",
    "    @classmethod\n",
    "    # 放宽pluscode\n",
    "    def loosen_blacklist(cls, df_orders, line, separator):\n",
    "        df_new = df_orders[df_orders.plus_code.apply(lambda x: str(x).startswith(getattr(line, 'code_id')[:separator]) if x else False)]\n",
    "        df_new = df_new.copy()\n",
    "        df_new.loc[:, 'plus_code'] = df_new.plus_code.apply(lambda x:x[:separator-1]+'+')\n",
    "        plus_codes_new = set(list(df_new.plus_code.unique()))\n",
    "        overdue_cnt = 0\n",
    "        apply_cnt = len(df_new)\n",
    "        for line in df_new.itertuples():\n",
    "            if getattr(line, 'overdue_days')>3:\n",
    "                overdue_cnt+=1\n",
    "        beans_pluscode=[]\n",
    "        for i in plus_codes_new:\n",
    "            beans_pluscode.append({\n",
    "                'code_id':i,\n",
    "                'apply_cnt':apply_cnt,\n",
    "                'overdue_cnt':overdue_cnt    \n",
    "            })\n",
    "        df_code_new = pd.DataFrame(beans_pluscode)\n",
    "        df_code_new['rate'] = df_code_new['overdue_cnt']/df_code_new['apply_cnt']\n",
    "        return df_code_new\n",
    "    \n",
    "    @classmethod\n",
    "    # 收缩pluscode\n",
    "    def tighten_blacklist(cls, df_orders, line, separator):\n",
    "        df_new = df_orders[df_orders.plus_code.apply(lambda x: str(x).startswith(getattr(line, 'code_id')[:separator]) if x else False)]\n",
    "        df_new = df_new.copy()\n",
    "        df_new.loc[:, 'plus_code'] = df_new.plus_code.apply(lambda x:x[:separator+1]+'+')\n",
    "        plus_codes_new = set(list(df_new[df_new.overdue_days>3].plus_code.unique()))\n",
    "        overdue_dic = defaultdict(int)\n",
    "        apply_dic = defaultdict(int)\n",
    "        for line in df_new.itertuples():\n",
    "            plus_code = getattr(line, 'plus_code')\n",
    "            if plus_code in plus_codes_new:\n",
    "                apply_dic[plus_code]+=1\n",
    "                if getattr(line, 'overdue_days')>3:\n",
    "                    overdue_dic[plus_code]+=1\n",
    "        beans_pluscode=[]\n",
    "        for i in plus_codes_new:\n",
    "            beans_pluscode.append({\n",
    "                'code_id':i,\n",
    "                'apply_cnt':apply_dic[i],\n",
    "                'overdue_cnt':overdue_dic[i]    \n",
    "            })\n",
    "        df_code_new = pd.DataFrame(beans_pluscode)\n",
    "        df_code_new['rate'] = df_code_new['overdue_cnt']/df_code_new['apply_cnt']\n",
    "        return df_code_new\n",
    "    \n",
    "    @classmethod\n",
    "    def get_final_blacklist(cls, orders_table):\n",
    "#         increase_orders = cls.get_orders_first()\n",
    "\n",
    "        _ = thread_map(cls.get_plus_code, orders_table, max_workers=10)\n",
    "        \n",
    "        df_orders = pd.DataFrame(orders_table)\n",
    "#         df_orders.to_csv(\"orders.csv\", index=False)\n",
    "        \n",
    "        plus_codes_notsliced = set(list(df_orders[df_orders.overdue_days>3].plus_code.unique()))\n",
    "        if None in plus_codes_notsliced:\n",
    "            plus_codes_notsliced.remove(None)\n",
    "        plus_codes=[]\n",
    "        for i in tqdm(plus_codes_notsliced):\n",
    "            plus_codes.append(i[:6]+'+')\n",
    "        plus_codes=set(plus_codes)\n",
    "        \n",
    "        df_code = cls.get_original_blacklist(orders_table, plus_codes)\n",
    "#         save_to_sql(df_code, 'super_original_pluscode', 'append')\n",
    "        \n",
    "        frames = []\n",
    "        frames.append(df_code[(df_code['apply_cnt']>10) & (df_code['apply_cnt']<30) & (df_code['rate']>.5)])\n",
    "        for line in tqdm(df_code.itertuples()):\n",
    "            if getattr(line, 'apply_cnt')<10:\n",
    "                df_code_a = cls.loosen_blacklist(df_orders, line, 6)\n",
    "                frames.append(df_code_a[(df_code_a['apply_cnt']>5) & (df_code_a['rate']>.5)])\n",
    "                for line in df_code_a.itertuples():\n",
    "                    if getattr(line, 'apply_cnt')<30:\n",
    "                        df_code_b = cls.loosen_blacklist(df_orders, line, 5)\n",
    "                        frames.append(df_code_b[(df_code_b['apply_cnt']>5) & (df_code_b['rate']>.5)])\n",
    "            elif getattr(line, 'apply_cnt')>30:\n",
    "                df_code_1 = cls.tighten_blacklist(df_orders, line, 6)\n",
    "                frames.append(df_code_1[(df_code_1['apply_cnt']>5) & (df_code_1['rate']>.5)])\n",
    "                for line in df_code_1.itertuples():\n",
    "                    if getattr(line, 'apply_cnt')>30:\n",
    "                        df_code_2 = cls.tighten_blacklist(df_orders, line, 7)\n",
    "                        frames.append(df_code_2[(df_code_2['apply_cnt']>5) & (df_code_2['rate']>.5)])\n",
    "        df_result = pd.concat(frames)\n",
    "        df_result = df_result.drop_duplicates(subset='code_id', keep='first', inplace=False, ignore_index=False)\n",
    "#         result.to_csv('pluscode_blacklist.csv', index=False)\n",
    "        return df_result, df_code\n",
    "\n",
    "\n",
    "    # 每天更新，向全量数据分析的结果上修改追加近14天到期的pluscode黑名单\n",
    "    @classmethod\n",
    "    def update_result(cls):\n",
    "        global df_total_result, df_total_original_rate\n",
    "        increase_orders = cls.increase_orders_first()\n",
    "        df_increase = cls.get_final_blacklist(increase_orders)\n",
    "        df_increase_result = df_increase[0]\n",
    "        df_increase_original_rate = df_increase[1]\n",
    "        df_total_result = pd.concat([df_total_result, df_increase_result]).groupby('code_id').sum().reset_index()\n",
    "        df_total_result['rate'] = df_total_result['overdue_cnt']/df_total_result['apply_cnt']\n",
    "        # 也记录下原始的六位pluscode分布\n",
    "        df_total_original_rate = pd.concat([df_total_original_rate, df_increase_original_rate]).groupby('code_id').sum().reset_index()\n",
    "        df_total_original_rate['rate'] = df_total_original_rate['overdue_cnt']/df_total_original_rate['apply_cnt']\n",
    "        df_total_result.to_csv('super_pluscode_blacklist.csv', index=False)\n",
    "        df_increase_original_rate.to_csv('super_pluscode_distribution.csv', index=False)\n",
    "        save_to_sql(df_total_result, 'super_pluscode_blacklist', 'replace')\n",
    "        save_to_sql(df_total_original_rate, 'super_pluscode_distribution', 'replace')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "097130f3-457e-4e34-9026-f937421b81e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_sql(df, table_name, behave:str):\n",
    "    print(f\">>> saving to sql {table_name}...\")\n",
    "    engine = create_engine(\n",
    "        'mysql+pymysql://mexico_risk:BupQ$H4UFNgvy5!#@10.10.1.153:3306/risk_center', pool_pre_ping=True)\n",
    "    df.to_sql(table_name, engine, index=False, if_exists=behave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a4e9c23-648e-4a5f-8a2f-82ccac1fd5a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bb1b85fbb3049d584fd7ea7e4ce9096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/601092 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f61453ddae3245a382f71ab8452ef973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/106501 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f48284e73944bb5a2e20bd7ffd92551",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/601092 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ed1e47d337b4eac802b313e6e536900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_orders = PlusCodeBlackList.total_orders_first()\n",
    "df_total = PlusCodeBlackList.get_final_blacklist(total_orders)\n",
    "df_total_result = df_total[0]\n",
    "df_total_original_rate = df_total[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "214a733c-2a94-44f6-9116-918312bddb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "@task(max_retries=3, retry_delay=timedelta(seconds=10), log_stdout=True)\n",
    "def result_output():\n",
    "    PlusCodeBlackList.update_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "990eafe6-e3da-4b02-95c6-b3e842d154d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74cffa10-4c44-4dd5-9f48-b6eb8092670f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flow URL: https://cloud.prefect.io/risk-doowintech-com-s-account/flow/365ad9dd-0ea4-4be6-baea-4ea96e0a3358\n",
      " └── ID: d2715fff-b063-4433-9e53-6880c534527d\n",
      " └── Project: mx-server\n",
      " └── Labels: ['ecs-64b9']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'d2715fff-b063-4433-9e53-6880c534527d'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "executor = LocalDaskExecutor(scheduler=\"threads\")\n",
    "\n",
    "schedule = IntervalSchedule(\n",
    "    start_date=pendulum.now().utcnow().add(seconds=3),\n",
    "    interval=timedelta(days=1)\n",
    ")\n",
    "\n",
    "with Flow(\n",
    "    \"mx_get_pluscode_blacklist\",\n",
    "    executor=executor,\n",
    "    schedule=schedule\n",
    ")as flow:\n",
    "    result_output()\n",
    "#     flow.run()\n",
    "flow.register(project_name='mx-server')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587178a7-f794-4c95-8bd3-92d8c4f867e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c490c06e-725d-4144-af34-0882a73951e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_code[(df_code['apply_cnt']>10) & (df_code['rate']>.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f849df1-91ec-4cf0-a0a8-76c9e428b36a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f4bef4-2937-4888-b5ba-3a8583950d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_75GQG"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-showcode": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
